{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get llada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e5c0c528b847c4a5f7cf08908ed294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "mpath = f\"/{...}/models/LLaDA-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=mpath, trust_remote_code=True,)\n",
    "model = AutoModel.from_pretrained(pretrained_model_name_or_path=mpath,trust_remote_code=True,\n",
    "                                   torch_dtype=torch.bfloat16, device_map='auto')\n",
    "# bf16 双卡加起来 16G 显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftext|>',\n",
       " '<|endoftext|>',\n",
       " '[CLS]',\n",
       " '<role>',\n",
       " '</role>',\n",
       " '<|arithmetic_start|>',\n",
       " '<|arithmetic_end|>',\n",
       " '<|number_start|>',\n",
       " '<|number_end|>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126080, 126081, 126082, 126340, 126341, 126342, 126343, 126344, 126345]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ġ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lily can run 12 kilometers per hour for 4 hours. After that, she runs 6 kilometers per hour\\n How many kilometers can she run in 8 hours\\n\\n\\nShe can run $12 \\\\              48 =boxed{{8}$}$.']\n",
      "['Lily can run 12 kilometers per hour for 4 hours. After that, she runs 6 kilometers per hour\\n How many kilometers can she run in 8 hours\\n\\n\\nShe can run $12 \\\\              48 =boxed{{8}$}$.']\n"
     ]
    }
   ],
   "source": [
    "# 假设这是你的 token ID 序列\n",
    "input_ids = [\n",
    "    [126348, 126081, 126081, 126081, 126081, 126081, 86059, 560, 2001, 220, 16, 17, 44137, 854, 6984, 352, 220, 19, 3871, 13, 4474, 378, 11, 1285, 9660, 220, 21, 44137, 854, 6984, 198, 2071, 1494, 44137, 560, 1285, 2001, 296, 220, 23, 3871, 126081, 198, 126081, 126081, 126081, 126081, 198, 198, 6572, 560, 2001, 558, 16, 17, 795, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 19, 23, 373, 32289, 90, 90, 23, 2536, 2536, 13, 126348, 126081]\n",
    "]\n",
    "\n",
    "input_ids2 =([126080, 126346,   3840, 126347,    198,    198,  86059,    560,   2001,\n",
    "            220,     16,     17,  44137,    854,   6984,    352,    220,     19,\n",
    "           3871,     13,   4474,    378,     11,   1285,   9660,    220,     21,\n",
    "          44137,    854,   6984,     13,   2071,   1494,  44137,    560,   1285,\n",
    "           2001,    296,    220,     23,   3871,     30, 126348, 126346,    598,\n",
    "          10450, 126347,    198,    198,  86059,    560,   2001,    558,     16,\n",
    "             17,    220,    220,    220,    220,    220,    220,     23,    220,\n",
    "            220,    220,    220,     23,     23,     23,     23, 126081, 126081,\n",
    "           2536,     90, 126081, 126081,   2536, 126081,     13, 126348, 126081])\n",
    "\n",
    "# 解码这个 token ID 序列\n",
    "decoded_text = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "decoded_text2 = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "# 输出解码后的文本\n",
    "print(decoded_text)\n",
    "print(decoded_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLaDAModelLM(\n",
       "  (model): LLaDAModel(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(126464, 4096)\n",
       "      (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "      (ln_f): RMSLayerNorm()\n",
       "      (blocks): ModuleList(\n",
       "        (0-31): 32 x LLaDALlamaBlock(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (act): SiLU()\n",
       "          (attn_out): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (ff_out): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (attn_norm): RMSLayerNorm()\n",
       "          (ff_norm): RMSLayerNorm()\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (ff_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (ff_out): Linear(in_features=4096, out_features=126464, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
